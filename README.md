##Files
Files included in this repo:
- 'README.md'
- 'run\_analysis.R': R script that process the data.  
- 'codebook.md': Shows information about the variables in the 'data\_mean.txt'  
- 'data\_mean.txt': A tidy data text file generated by 'run\_analysis.R'.  
- 'feature\_variables.txt': A complete list of feature variables appear in the 'data\_mean.txt' just for your reference.

---   
Code for reading 'data_mean.txt' back into R:   

    read.table("./data_mean.txt", header = T) 

##'run\_analysis.R'  
###**What the script does:**
  
1. Identifies only the measurements on the mean and standard deviation for each measurement from 'features.txt' and find what columns to read from the training and the test sets. 
2. Selectively reads the training and the test sets to create one data set.
3. Appropriately labels the data set with descriptive variable names. 
4. Uses descriptive activity names to name the activities in the data set (`merge()` the activity names to the data sets).
5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.

(**NOTE**: 'run\_analysis.R' requires 'getdata-projectfiles-UCI HAR Dataset.zip' in the working directory to work.)  

##Data Processing Strategy
####Skip Columns
The script first identifies target features from `'features.txt'` with use of regular expression and then slectively skip columns when reading the vector-feature files (e.g. `'X\_test.txt'`).  

The major part that slows the program down is when reading in the data file containing 561 columns of feature vectors. Because the 3 empty spaces at the beginning of every line in the feature-vector files makes the file _non-regular_, so we can't use the much more efficient `fread` from `{data.table}` package because it only read _regular_ delimited files. So we have to use `read.table` from the `{base}`, which becomes quite slow if the data size get bigger. There are total of 10,299 rows in train and test sets combined, so we are dealing with a **561 x 10,299** matrix. Since this project only want the _"measurements on the mean and standard deviation for each measurement"_ from the 561-feature vector, which is a small subset (66 features exactly). Fortunately `read.table` allows skip columns by provide `"NULL"` string in `colClasses` for each columns to be skipped. In the end we only need to read a **561 x 66** matrix, **88%** smaller than the original data set. 
 
---
####Use `data.table` instead of `data.frame`
A data.table is much faster and memorry efficent than a data.frame. The intutive syntax makes merging (Step 4) and calculating the averages of each variable for each activity and each subject (Step 5) very easy. 